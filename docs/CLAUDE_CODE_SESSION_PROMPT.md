# Claude Code Session: PSEC Baseline Hunter — Personalized Summary Feature

## Quick Context (Read First)

You're working on **PSEC Baseline Hunter**, a Next.js app that helps non-technical users understand network security scan results. The repo is at `~/Desktop/psec-baseline-hunter` on branch `feature/phase2-run-registry`.

**Current state:** The app works end-to-end. We just ran a fresh scan of the "orange-network" (home LAN) and successfully uploaded it. The Scorecard shows:
- 12 hosts, 14 open ports, 7 services, 5 risk ports
- Analysis Summary card with prioritized actions
- Risk exposures with affected host counts

**What's missing:** The Scorecard is accurate but reads like a security tool. Non-technical users (busy parents, attorneys, small business owners) need plain-English explanations tailored to their situation.

---

## Session Goal: Implement "Personalized Plain-English Summary"

Build a feature that lets users click "Explain this for my situation" on the Scorecard and receive an LLM-generated report tailored to their technical level, profession, and context (kids at home, works from home, handles sensitive data, etc.).

---

## Implementation Spec (from new_feature.md)

### Where it lives
**Scorecard page** (`/scorecard`) — add a new card under "Analysis Summary":
- Title: **Personalized Explanation**
- Subtitle: "Generate a plain-English report tailored to your role and household."
- Primary button: **Generate report**
- Secondary button: **Customize** (opens modal)

### User profile modal fields

**Required:**
- `technicalLevel`: `non_technical` (default) | `some_technical` | `technical`

**Optional:**
- `professionOrRole`: string (e.g., "Attorney", "Small business owner", "Stay-at-home parent")
- `context`: checkboxes
  - `works_from_home`
  - `travels_often`
  - `young_children_in_home`
  - `handles_sensitive_client_data`
  - `uses_iot_devices`
- `audience`: `self` | `spouse_family` | `IT_vendor` | `executive_summary`
- `tone`: `concise` | `normal` | `detailed`
- `includeSensitiveDetails`: boolean (default **false** — redacts IPs/hostnames)

**Persistence:** Save to localStorage so returning users don't re-enter.

### API endpoint

`POST /api/llm/scorecard-summary`

**Request payload:**
```json
{
  "runId": "orange-network - 2026-01-26_2126_baselinekit_v0",
  "userProfile": {
    "technicalLevel": "non_technical",
    "professionOrRole": "Attorney",
    "context": ["works_from_home", "handles_sensitive_client_data"],
    "audience": "self",
    "tone": "normal",
    "includeSensitiveDetails": false
  },
  "scorecardSummary": {
    "totalHosts": 12,
    "openPorts": 14,
    "services": 7,
    "riskPorts": 5,
    "analysisSummary": "Scan shows 12 hosts with 14 open ports. 4 critical exposures...",
    "recommendedActions": [...],
    "riskExposures": [...]
  }
}
```

**Response:**
```json
{
  "markdown": "## Executive summary\n...",
  "meta": { "provider": "anthropic", "model": "claude-3-5-sonnet", "cached": false }
}
```

### LLM output format (enforce these headings)
1. **Executive summary** (3–5 bullets)
2. **Why this matters for you** (tie to profession + context)
3. **Top 3 actions (do these first)** (clear, non-jargon)
4. **What could happen if ignored** (realistic, not fear-mongering)
5. **What I need from you** (questions to identify devices)
6. **Notes / limitations**

### Fallback behavior
If no API key configured:
- Show friendly message: "LLM summary not configured. Showing standard explanation."
- Generate a basic rule-based summary locally (port → plain explanation mapping)

---

## Files to Create/Update

### New files
- `src/components/scorecard/PersonalizedSummaryCard.tsx` — the main card component
- `src/components/scorecard/PersonalizedSummaryModal.tsx` — the customize modal
- `src/components/scorecard/MarkdownViewer.tsx` — render LLM markdown output
- `src/lib/types/userProfile.ts` — TypeScript types for user profile
- `src/lib/llm/provider.ts` — provider abstraction (Anthropic/OpenAI/fallback)
- `src/lib/llm/prompt-scorecard.ts` — prompt builder
- `src/app/api/llm/scorecard-summary/route.ts` — API route

### Update
- `src/app/(dashboard)/scorecard/page.tsx` — add PersonalizedSummaryCard
- `.env.example` — add `ANTHROPIC_API_KEY`, `OPENAI_API_KEY`, model vars

---

## Security & Privacy (Non-Negotiable)

1. **Default to redaction** — do NOT send internal IPs/hostnames to LLM
2. **Explicit opt-in** for sensitive details with clear warning
3. **Never store raw scan payloads** on server for this feature
4. **Add disclaimer** in UI: "This summary may be generated by an AI model; verify before acting."
5. **Basic rate limiting** — 10 requests/minute per IP

---

## Implementation Order

### Phase 1: Types and API route (foundation)
1. Create `src/lib/types/userProfile.ts` with TypeScript interfaces
2. Create `src/lib/llm/provider.ts` with provider detection logic
3. Create `src/lib/llm/prompt-scorecard.ts` with prompt builder
4. Create `src/app/api/llm/scorecard-summary/route.ts`
5. Test API route with curl/Postman

### Phase 2: UI components
6. Create `src/components/scorecard/MarkdownViewer.tsx`
7. Create `src/components/scorecard/PersonalizedSummaryModal.tsx`
8. Create `src/components/scorecard/PersonalizedSummaryCard.tsx`
9. Update Scorecard page to include the new card

### Phase 3: Polish
10. Add localStorage persistence for user profile
11. Add loading states and error handling
12. Add "Copy" and "Download .md" buttons
13. Add caching by `(runId + userProfileHash)`

---

## Reference: Current Scorecard Data Shape

The Scorecard already has this data available (from your orange-network scan):

```typescript
interface ScorecardData {
  totalHosts: number;          // 12
  openPorts: number;           // 14
  services: number;            // 7
  riskPorts: number;           // 5
  analysisSummary: string;     // "Scan shows 12 hosts..."
  recommendedActions: Array<{
    action: string;
    port: number;
    hostsAffected: number;
    priority: 'P0' | 'P1' | 'P2';
  }>;
  riskExposures: Array<{
    port: number;
    protocol: string;
    service: string;
    priority: 'P0' | 'P1' | 'P2';
    hostsAffected: number;
    hosts?: string[];  // IPs - redact unless opted in
  }>;
  topPorts: Array<{
    port: number;
    protocol: string;
    service: string;
    hostsAffected: number;
  }>;
}
```

---

## Example Prompt for LLM

```
You are a security assistant explaining network scan results to a non-technical user.

User profile:
- Technical level: non-technical
- Role: Attorney who works from home
- Context: handles sensitive client data, young children in home
- Audience: self
- Tone: normal

Scan summary (IPs redacted):
- 12 devices on network
- 14 open ports total
- 5 risky ports detected:
  - SOCKS proxy (port 1080) on 2 devices — P0
  - SMB file sharing (port 445) on 2 devices — P0
  - NetBIOS (port 139) on 2 devices — P0

Generate a plain-English report with these sections:
1. Executive summary (3-5 bullets)
2. Why this matters for you (tie to attorney + sensitive data + kids)
3. Top 3 actions (do these first)
4. What could happen if ignored
5. What I need from you (questions to identify devices)
6. Notes / limitations

Keep it practical. No jargon. Prioritize by actual risk, not hype.
```

---

## Definition of Done

- [ ] Scorecard page includes "Personalized Explanation" card
- [ ] Modal allows user to set technical level + role + context
- [ ] Clicking Generate produces a markdown report
- [ ] Redaction is default; opt-in for IPs is explicit with warning
- [ ] Fallback summary works without API key
- [ ] localStorage persists user preferences
- [ ] Basic rate limiting in API route
- [ ] "Copy" and "Download" buttons work
- [ ] Lint/build passes

---

## Start Here

Begin by reading:
1. `src/app/(dashboard)/scorecard/page.tsx` — understand current structure
2. `src/lib/services/` — see how data flows
3. `CLAUDE.md` — check existing project conventions

Then:
1. Create the types file first (`src/lib/types/userProfile.ts`)
2. Build the API route with fallback logic
3. Add the UI components
4. Wire it all together

Let me know what you find in the codebase and we'll iterate.
